% HMC Math dept HW template example
% v0.04 by Eric J. Malm, 10 Mar 2005
\documentclass[12pt,letterpaper,boxed]{hmcpset}

% set 1-inch margins in the document
\usepackage[margin=1in]{geometry}

% include this if you want to import graphics files with /includegraphics
\usepackage{graphicx,siunitx,cancel,scrextend,amsthm, amssymb, enumerate,
  hyperref, parskip}

\input{macros.tex}

\DeclareSIUnit\year{yr}
\newcommand{\inden}{\begin{addmargin}[2em]{0em}}

% info for header block in upper right hand corner
\name{Joseph Gardi}
\class{Big Data}
\assignment{Homework \#6}
\duedate{03/11/2019}

\begin{document}
\begin{problem}[1]
\textbf{(Murphy 11.2 - EM for Mixtures of Gaussians)} Show that the M step for ML
estimation of a mixture of Gaussians is given by
\begin{align*}
    \mub_k &= \frac{\sum_i r_{ik}\xx_i}{r_k}\\
    \Sigmab_k &= \frac{1}{r_k}\sum_i r_{ik}(\xx_i - \mub_k)(\xx_i - \mub_k)^\T = \frac{1}{r_k}\sum_i r_{ik}\xx_i\xx_i^\T - r_k\mub_k\mub_k^\T.
\end{align*}
\end{problem}
\begin{solution}
  For the maximization step we find the $\mu_k$ and $\Sigma_k$ that maximizes
  the log likelihood. The book gives us the log likelihood.
  \begin{align*}
    \mu_k &= \argmax_{\mu_k} \left[ -\frac{1}{2} \sum_i r_{ik} (log |\Sigma_k| + (x_i - \mu_k)^T \Sigma_k^{-1}(x_i - \mu_k))  \right] \\
    &= \argmin_{\mu_k} \sum_i r_{ik} (x_i - \mu_k)^T \Sigma_k^{-1}(x_i - \mu_k) \\
  \end{align*}
  Now to find compute the minimum I take the derivative $\mu_k$and set it to 0. Then
  solve. The derivative with respect to $\mu_k$ is,
  \begin{align*}
    \frac{\partial}{\partial \mu_k} \left( \sum_i r_{ik} (x_i - \mu_k)^T \Sigma_k^{-1}(x_i - \mu_k) \right) \\
    &= \sum_i r_{ik} \left( \Sigma_k^{-1}(x_i -\mu_k )  + \Sigma_k^{-T} (x_i - \mu_k) \right) \\
    &= 2 \Sigma_k^{-1} \sum_i r_{ik} (x_i -\mu_k ) & \text{Since $\Sigma^{-1}$ is symetric }
  \end{align*}
  Now I set the derivative equal to $0$ and solve for $\mu_k$,
  \begin{align*}
    2 \Sigma_k^{-1} \sum_i r_{ik} (x_i -\mu_k ) &= 0 \\
    \implies \sum_i r_{ik} (x_i  -\mu_k ) &= 0 \\
    \implies \sum_i r_{ik} x_i &= \sum_i r_{ik} \mu_k \\
    \implies \mu_k &= \frac{\sum_i r_{ik} x_i}{\sum_i r_{ik}} \\
    &= \boxed{\frac{\sum_i r_{ik} x_i}{r_k}}
  \end{align*}
  I used the solution for this part. \\
  Now I'll repeat to find $\Sigma_k^{-1}$,
  \begin{align*}
    \Sigma_k &= \argmax_{\Sigma_k} \left[ -\frac{1}{2} \sum_i r_{ik} (log |\Sigma_k| + (x_i - \mu_k)^T \Sigma_k^{-1}(x_i - \mu_k))  \right] \\
    &= \argmin_{\Sigma_k} \sum_i r_{ik} (log |\Sigma_k| + (x_i - \mu_k)^T \Sigma_k^{-1}(x_i - \mu_k))
  \end{align*}
  The derivative with respect to $\Sigma_k^{-1}$ is,
  \begin{align*}
    &\frac{\partial}{\partial \Sigma_k^{-1}} \sum_i r_{ik} (log |\Sigma_k| + (x_i - \mu_k)^T \Sigma_k^{-1}(x_i - \mu_k)) \\
    &= \sum_i r_{ik} (\frac{1}{|\Sigma_k|} |\Sigma_k| \Sigma_k^{-1} - \Sigma_k^{-1}(x_i - \mu_k) (x_i -\mu_k)^T \Sigma_k^{-1}) \\
    &= \Sigma_k^{-1} \sum_i r_{ik} (I - (x_i - \mu_k) (x_i -\mu_k)^T \Sigma_k^{-1}) \\
  \end{align*}
  Set the derivative equal to 0 and solve for $\Sigma_k$,
  \begin{align*}
    \Sigma_k^{-1} \sum_i r_{ik} (I - (x_i - \mu_k) (x_i -\mu_k)^T \Sigma_k^{-1}) &= 0 \\
    \implies \sum_i r_{ik} (I - (x_i - \mu_k) (x_i -\mu_k)^T \Sigma_k^{-1}) &= 0 \\
    \implies I \sum_i r_{ik} &= \left( \sum_i r_{ik} (x_i - \mu_k) (x_i -\mu_k)^T \right) \Sigma_K^{-1} \\
    \implies \Sigma_k \sum_i r_{ik} &= \sum_i r_{ik} (x_i - \mu_k) (x_i -\mu_k)^T \\
    \implies \Sigma_k &= \frac{\sum_i r_{ik} (x_i - \mu_k) (x_i -\mu_k)^T}{\sum_i r_{ik}}
  \end{align*}
\end{solution}
\newpage



\begin{problem}[2]
\textbf{(SVD Image Compression)}
In this problem, we will use the image of a scary clown online to perform image compression.  In the starter code, we have already load the image into a matrix/array for you. However, you might need internet connection to access the image and therefore successfully run the starter code. The code requires Python library Pillow in order to run.
\newline
\newline 
Plot the progression of the 100 largest singular values for the original image
and a randomly shuffled version of the same image (all on the same plot). In a single figure plot
a grid of four images: the original image, and a rank $k$ truncated SVD approximation of the original
image for $k\in\{2,10,20\}$.

\end{problem}
\begin{solution}

\end{solution}
\newpage

\end{document}
